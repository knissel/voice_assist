# Voice Assistant with Gemini Flash

A voice-controlled assistant powered by Google Gemini Flash that can control smart home devices, manage Bluetooth connections, and answer questions using natural language.

## Features

- üé§ **Wake Word Detection**: Uses Porcupine for "americano", "computer", or custom wake words
- üó£Ô∏è **Speech-to-Text**: Local transcription with Whisper.cpp
- ü§ñ **AI Processing**: Google Gemini 2.0 Flash Lite for natural language understanding
- üîß **Function Calling**: Control smart home lights, Bluetooth devices, audio routing, and YouTube Music
- üîä **Text-to-Speech**: Ultra-low latency local TTS using Piper (~100-200ms)
- ‚å®Ô∏è **Push-to-Talk Mode**: Alternative mode using spacebar to activate
- üéµ **YouTube Music**: Play songs, albums, artists, and playlists
- üîâ **Volume Control**: Adjust system volume with voice commands

## Prerequisites

- Python 3.9+
- macOS or Linux (Raspberry Pi supported)
- [Whisper.cpp](https://github.com/ggerganov/whisper.cpp) installed locally
- Google Gemini API key
- Porcupine access key (for wake word detection)
- Piper TTS voice model (for local text-to-speech)

## Installation

1. **Clone the repository**
   ```bash
   git clone <your-repo-url>
   cd voice_assist
   ```

2. **Create a virtual environment**
   ```bash
   python3 -m venv .venv
   source .venv/bin/activate
   ```

3. **Install system dependencies**
   ```bash
   # Linux/Raspberry Pi
   sudo apt-get update
   sudo apt-get install libportaudio2
   ```

4. **Install Python dependencies**
   ```bash
   pip install -r requirements.txt
   ```

5. **Set up Whisper.cpp**
   ```bash
   # Clone and build whisper.cpp
   git clone https://github.com/ggerganov/whisper.cpp.git
   cd whisper.cpp
   make
   
   # Download a model (tiny is recommended for speed)
   bash ./models/download-ggml-model.sh tiny
   cd ..
   ```

6. **Set up Piper TTS**
   
   Download a voice model (see [PIPER_TTS_SETUP.md](docs/PIPER_TTS_SETUP.md) for details):
   ```bash
   mkdir -p piper_models
   cd piper_models
   wget https://huggingface.co/rhasspy/piper-voices/resolve/main/en/en_US/lessac/medium/en_US-lessac-medium.onnx
   wget https://huggingface.co/rhasspy/piper-voices/resolve/main/en/en_US/lessac/medium/en_US-lessac-medium.onnx.json
   cd ..
   ```

7. **Configure environment variables**
   
   Copy the example environment file:
   ```bash
   cp .env.example .env
   ```
   
   Edit `.env` and add your API keys:
   ```bash
   # Gemini API Configuration
   GEMINI_API_KEY=your_gemini_api_key_here
   MODEL_NAME=gemini-flash-lite-latest
   
   # Porcupine Wake Word Configuration
   PORCUPINE_ACCESS_KEY=your_porcupine_access_key_here
   
   # Whisper Configuration (update paths if needed)
   WHISPER_PATH=/path/to/whisper.cpp/build/bin/whisper-cli
   MODEL_PATH=/path/to/whisper.cpp/models/ggml-tiny.bin
   
   # Piper TTS Configuration (optional, uses default if not set)
   # PIPER_MODEL=/path/to/your/piper/model.onnx
   
   # Control4 Configuration (if using Control4 smart home)
   CONTROL4_USERNAME=your_username
   CONTROL4_PASSWORD=your_password
   CONTROL4_CONTROLLER_IP=192.168.x.x
   ```

## Getting API Keys

### Google Gemini API Key
1. Visit [Google AI Studio](https://aistudio.google.com/app/apikey)
2. Sign in with your Google account
3. Create a new API key
4. Copy the key to your `.env` file

### Porcupine Access Key
1. Visit [Picovoice Console](https://console.picovoice.ai/)
2. Sign up for a free account
3. Create an access key
4. Copy the key to your `.env` file

### Piper TTS Voice Models
1. See [PIPER_TTS_SETUP.md](docs/PIPER_TTS_SETUP.md) for detailed setup
2. Download voice models from [Piper Voices](https://huggingface.co/rhasspy/piper-voices)
3. Recommended: `en_US-lessac-medium` for Raspberry Pi
4. Completely free and runs locally (no API costs)

## Usage

### Wake Word Mode (Continuous Listening)

Run the wake word listener that responds to "americano" or "computer":

```bash
python wakeword.py
```

Say the wake word, then speak your command. The assistant will:
1. Detect the wake word
2. Record your voice command (4 seconds)
3. Transcribe it using Whisper.cpp
4. Process with Gemini Flash Lite
5. Execute actions or respond verbally with ultra-fast local TTS

**Recommended for Raspberry Pi** - hands-free operation without keyboard

### Push-to-Talk Mode

Run the push-to-talk assistant:

```bash
python run_assistant.py
```

- Press **SPACE** to record a command
- Press **ESC** to quit

## Supported Commands

### Lighting Control
- "Turn on the kitchen lights"
- "Set kitchen island to 50%"
- "Turn off the family room lights"
- "Dim the foyer lights"

**Device IDs:**
- Kitchen Cans: 85
- Kitchen Island: 95
- Family Room: 204
- Foyer: 87
- Stairs: 89

### Bluetooth & Audio Control
- "Connect to [device name]"
- "Disconnect Bluetooth"
- "Route audio to Bluetooth"
- "Turn up the volume"
- "Set volume to 50%"
- "Turn down the volume"

### YouTube Music
- "Play [song name]"
- "Play [artist name]"
- "Play [album name]"
- "Stop the music"
- "Pause"

### General Questions
Ask any question and Computer will respond with concise answers.

## Project Structure

```
voice_assist/
‚îú‚îÄ‚îÄ .env                    # Environment variables (not in git)
‚îú‚îÄ‚îÄ .env.example           # Template for environment variables
‚îú‚îÄ‚îÄ .gitignore             # Git ignore rules
‚îú‚îÄ‚îÄ requirements.txt       # Python dependencies
‚îú‚îÄ‚îÄ README.md             # This file
‚îú‚îÄ‚îÄ run_assistant.py      # Push-to-talk mode (main entry point)
‚îú‚îÄ‚îÄ wakeword.py           # Wake word detection mode (main entry point)
‚îú‚îÄ‚îÄ main.py               # Basic example script
‚îú‚îÄ‚îÄ docs/                 # Documentation
‚îÇ   ‚îú‚îÄ‚îÄ RASPBERRY_PI_SETUP.md
‚îÇ   ‚îú‚îÄ‚îÄ PIPER_TTS_SETUP.md
‚îÇ   ‚îú‚îÄ‚îÄ YOUTUBE_MUSIC_SETUP.md
‚îÇ   ‚îú‚îÄ‚îÄ STOP_AUDIO_USAGE.md
‚îÇ   ‚îî‚îÄ‚îÄ VOLUME_CONTROL_USAGE.md
‚îú‚îÄ‚îÄ tests/                # Test files
‚îÇ   ‚îú‚îÄ‚îÄ test_volume_control.py
‚îÇ   ‚îú‚îÄ‚îÄ test_stop_music.py
‚îÇ   ‚îú‚îÄ‚îÄ test_youtube_music.py
‚îÇ   ‚îî‚îÄ‚îÄ ... (other test files)
‚îú‚îÄ‚îÄ scripts/              # Utility scripts
‚îÇ   ‚îú‚îÄ‚îÄ setup_youtube_music.py
‚îÇ   ‚îú‚îÄ‚îÄ find_devices.py
‚îÇ   ‚îú‚îÄ‚îÄ find_scenes.py
‚îÇ   ‚îî‚îÄ‚îÄ ... (other utility scripts)
‚îú‚îÄ‚îÄ tools/                # Core tool modules
‚îÇ   ‚îú‚îÄ‚îÄ registry.py       # Tool definitions and dispatch
‚îÇ   ‚îú‚îÄ‚îÄ control4_tool.py  # Control4 smart home integration
‚îÇ   ‚îú‚îÄ‚îÄ lights.py         # Lighting control utilities
‚îÇ   ‚îú‚îÄ‚îÄ bluetooth.py      # Bluetooth device management
‚îÇ   ‚îú‚îÄ‚îÄ audio.py          # Audio routing and volume control
‚îÇ   ‚îî‚îÄ‚îÄ youtube_music.py  # YouTube Music integration
‚îî‚îÄ‚îÄ whisper.cpp/          # Whisper.cpp installation (gitignored)
```

## Customization

### Change Wake Words

Edit `wakeword.py` line 161:
```python
keywords=['americano', 'computer']  # Change to your preferred wake words
```

Or use a custom wake word:
1. Train a custom wake word at [Picovoice Console](https://console.picovoice.ai/)
2. Download the `.ppn` file
3. Update the keywords parameter:
```python
keywords=['/path/to/custom_wakeword.ppn']
```

### Change Voice Model

Download a different Piper voice model and update your `.env`:
```bash
PIPER_MODEL=/path/to/different/model.onnx
```

Available voices: Browse [Piper Voices](https://huggingface.co/rhasspy/piper-voices/tree/main)

Popular options:
- `en_US-lessac-medium` - Clear, neutral (recommended)
- `en_US-amy-medium` - British English female
- `en_US-ryan-medium` - American English male

See [PIPER_TTS_SETUP.md](docs/PIPER_TTS_SETUP.md) for more voice options

### Add New Tools

1. Define your function in a new file or existing tool file
2. Add the function declaration to `tools/registry.py` in `GEMINI_TOOLS`
3. Add the function to `TOOL_FUNCTIONS` mapping
4. The dispatcher will automatically handle calls

## Profiling & Debugging

### CPU Profiling with py-spy
```bash
# Install
pip install py-spy

# Profile running assistant (requires sudo on Linux)
sudo py-spy top --pid $(pgrep -f wakeword.py)

# Generate flame graph
sudo py-spy record -o profile.svg --pid $(pgrep -f wakeword.py)
```

### Memory Profiling
```bash
pip install memory_profiler
python -m memory_profiler wakeword.py
```

### cProfile for Function-Level Analysis
```bash
python -m cProfile -s cumtime wakeword.py 2>&1 | head -50
```

### Audio Debugging
```bash
# List audio devices
python -c "import pyaudio; p = pyaudio.PyAudio(); [print(i, p.get_device_info_by_index(i)['name']) for i in range(p.get_device_count())]"

# Test recording (Linux)
arecord -d 5 -f S16_LE -r 16000 test.wav
aplay test.wav

# Test recording (macOS)
rec -r 16000 -c 1 test.wav trim 0 5
play test.wav
```

### Latency Measurement
The assistant logs timing for each stage. Look for:
- `üéß Transcribing...` ‚Üí ASR latency
- `üß† Processing...` ‚Üí LLM latency  
- `üí¨` ‚Üí TTS start

## Remote Deployment

Deploy code changes to your Raspberry Pi without physical access.

### Prerequisites

1. **SSH key authentication** set up with your Pi:
   ```bash
   # Generate SSH key if you don't have one
   ssh-keygen -t ed25519
   
   # Copy to Pi
   ssh-copy-id pi@raspberrypi.local
   ```

2. **rsync** available on your dev machine:
   - **Windows**: Install via WSL, Git Bash, or [cwRsync](https://itefix.net/cwrsync)
   - **macOS/Linux**: Pre-installed

3. **Configure deployment**:
   ```bash
   cp deploy.config.example deploy.config
   # Edit deploy.config with your Pi's hostname/IP
   ```

### Deploy Commands

**PowerShell (Windows):**
```powershell
.\deploy.ps1 --all              # Deploy everything and restart
.\deploy.ps1 --ui               # Deploy UI only (no restart needed)
.\deploy.ps1 --wakeword         # Deploy wakeword code and restart
.\deploy.ps1 --wakeword --logs  # Deploy and tail logs
.\deploy.ps1 --restart          # Just restart the service
.\deploy.ps1 --dry-run --all    # Preview what would be deployed
```

**Bash (WSL/Git Bash/Linux/macOS):**
```bash
./deploy.sh --all              # Deploy everything and restart
./deploy.sh --ui               # Deploy UI only
./deploy.sh --wakeword --logs  # Deploy wakeword and show logs
```

### What Gets Deployed

| Flag | Files | Restart |
|------|-------|---------|
| `--ui` | `ui/` | No |
| `--wakeword` | `wakeword.py`, `core/`, `tools/`, `adapters/`, `schemas/` | Yes |
| `--all` | Everything above + config files | Yes |

## Deployment as systemd Service

### Install Service (Raspberry Pi)

1. Copy the service file:
```bash
sudo cp voice-assistant.service /etc/systemd/system/
```

2. Edit paths if needed:
```bash
sudo nano /etc/systemd/system/voice-assistant.service
```

3. Enable and start:
```bash
sudo systemctl daemon-reload
sudo systemctl enable voice-assistant
sudo systemctl start voice-assistant
```

4. Check status:
```bash
sudo systemctl status voice-assistant
journalctl -u voice-assistant -f  # Live logs
```

### Service Management
```bash
sudo systemctl stop voice-assistant     # Stop
sudo systemctl restart voice-assistant  # Restart
sudo systemctl disable voice-assistant  # Disable auto-start
```

## Troubleshooting

### "No speech detected"
- Check microphone permissions
- Speak louder or closer to the microphone
- Increase `RECORD_SECONDS` in the script

### "Gemini API failed"
- Verify your API key in `.env`
- Check your internet connection
- Ensure you haven't exceeded API rate limits

### Wake word not detecting
- Verify Porcupine access key
- Try speaking the wake word more clearly
- Check microphone input levels

### Whisper transcription errors
- Ensure Whisper.cpp is properly built
- Verify paths in `.env` are correct
- Try a different model (base or small for better accuracy)

## Contributing

Feel free to submit issues and pull requests!

## License

MIT License - feel free to use this project for personal or commercial purposes.

## Acknowledgments

- [Google Gemini](https://ai.google.dev/) for the LLM
- [Piper](https://github.com/rhasspy/piper) for ultra-fast local text-to-speech
- [Whisper.cpp](https://github.com/ggerganov/whisper.cpp) for speech recognition
- [Porcupine](https://picovoice.ai/platform/porcupine/) for wake word detection
- [pyControl4](https://github.com/lawtancool/pyControl4) for Control4 integration
